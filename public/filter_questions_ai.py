#!/usr/bin/env python3
"""
Script para filtrar quest√µes do ENEM por disciplina usando IA (Groq API)
Autor: Pergamo
Data: 2024
"""

import os
import json
import requests
import time
from pathlib import Path
from typing import Dict, List, Any, Optional
import argparse

# Configura√ß√£o da API Groq
GROQ_API_URL = "https://api.groq.com/openai/v1/chat/completions"
GROQ_MODEL = "llama-3.1-8b-instant"

# Mapeamento de √°reas para disciplinas
AREA_TO_DISCIPLINES = {
    "ciencias-humanas": ["historia", "geografia", "filosofia", "sociologia"],
    "ciencias-natureza": ["biologia", "quimica", "fisica"],
    "linguagens": ["portugues", "literatura", "artes", "ingles", "espanhol"],
    "matematica": ["matematica"]
}

class QuestionFilter:
    def __init__(self, api_key: str, base_path: str = "."):
        self.api_key = api_key
        self.base_path = Path(base_path)
        self.processed_count = 0
        self.total_count = 0
        self.failed_count = 0
        self.skipped_count = 0
        
        # Rate limiting
        self.request_times = []  # Lista de timestamps das requisi√ß√µes
        self.token_usage = []    # Lista de tokens usados por minuto
        self.max_requests_per_70s = 30
        self.max_tokens_per_minute = 6000
        
        # Sistema de backoff exponencial
        self.consecutive_errors = 0
        self.base_delay = 3  # Delay base em segundos
        self.max_delay = 120    # Delay m√°ximo em segundos
        self.backoff_multiplier = 1.5  # Multiplicador para backoff
        
        # Log de erros
        self.error_log = []
        self.failed_questions = []
        self.log_file = self.base_path / "filter_errors.log"
    
    def _log_error(self, question_path: Path, error_type: str, error_message: str, area: str = None):
        """Registra um erro no log"""
        timestamp = time.strftime("%Y-%m-%d %H:%M:%S")
        error_entry = {
            "timestamp": timestamp,
            "question_path": str(question_path),
            "error_type": error_type,
            "error_message": error_message,
            "area": area
        }
        self.error_log.append(error_entry)
        self.failed_questions.append(question_path)
        
        # Caminho absoluto para o log (clic√°vel)
        absolute_path = question_path.resolve()
        
        # Salvar no arquivo de log
        with open(self.log_file, 'a', encoding='utf-8') as f:
            f.write(f"[{timestamp}] {error_type}: {absolute_path} (√°rea: {area})\n")
            f.write(f"  Erro: {error_message}\n\n")
    
    def _save_progress(self, year: int, processed_questions: list):
        """Salva o progresso atual"""
        progress_file = self.base_path / f"progress_{year}.json"
        progress_data = {
            "year": year,
            "processed_questions": processed_questions,
            "timestamp": time.time(),
            "processed_count": self.processed_count,
            "failed_count": self.failed_count,
            "skipped_count": self.skipped_count
        }
        
        with open(progress_file, 'w', encoding='utf-8') as f:
            json.dump(progress_data, f, ensure_ascii=False, indent=2)
    
    def _load_progress(self, year: int) -> list:
        """Carrega o progresso salvo"""
        progress_file = self.base_path / f"progress_{year}.json"
        if progress_file.exists():
            try:
                with open(progress_file, 'r', encoding='utf-8') as f:
                    progress_data = json.load(f)
                return progress_data.get("processed_questions", [])
            except Exception as e:
                print(f"‚ö†Ô∏è  Erro ao carregar progresso: {e}")
        return []
    
    def _calculate_backoff_delay(self) -> float:
        """Calcula o delay baseado no backoff exponencial"""
        if self.consecutive_errors == 0:
            return self.base_delay
        
        # F√≥rmula: base_delay * (backoff_multiplier ^ consecutive_errors)
        delay = self.base_delay * (self.backoff_multiplier ** self.consecutive_errors)
        
        # Limitar ao delay m√°ximo
        return min(delay, self.max_delay)
    
    def _reset_backoff(self):
        """Reseta o contador de erros consecutivos"""
        self.consecutive_errors = 0
    
    def _increment_backoff(self):
        """Incrementa o contador de erros consecutivos"""
        self.consecutive_errors += 1
    
    def _clean_old_requests(self):
        """Remove requisi√ß√µes antigas (mais de 70 segundos)"""
        current_time = time.time()
        self.request_times = [t for t in self.request_times if current_time - t < 70]
    
    def _clean_old_tokens(self):
        """Remove tokens antigos (mais de 1 minuto)"""
        current_time = time.time()
        self.token_usage = [(t, tokens) for t, tokens in self.token_usage if current_time - t < 60]
    
    def _can_make_request(self, estimated_tokens: int = 100) -> bool:
        """Verifica se pode fazer uma requisi√ß√£o respeitando os limites"""
        self._clean_old_requests()
        self._clean_old_tokens()
        
        # Verificar limite de requisi√ß√µes (30 a cada 70s)
        if len(self.request_times) >= self.max_requests_per_70s:
            return False
        
        # Verificar limite de tokens (6K por minuto)
        current_tokens = sum(tokens for _, tokens in self.token_usage)
        if current_tokens + estimated_tokens > self.max_tokens_per_minute:
            return False
        
        return True
    
    def _wait_for_rate_limit(self, estimated_tokens: int = 100):
        """Aguarda at√© poder fazer uma requisi√ß√£o com backoff exponencial"""
        while not self._can_make_request(estimated_tokens):
            # Calcular delay baseado no backoff exponencial
            backoff_delay = self._calculate_backoff_delay()
            
            if len(self.request_times) >= self.max_requests_per_70s:
                # Aguardar at√© a requisi√ß√£o mais antiga sair da janela de 70s
                oldest_request = min(self.request_times)
                wait_time = max(70 - (time.time() - oldest_request) + 1, backoff_delay)
                print(f"‚è≥ Aguardando {wait_time:.1f}s para liberar requisi√ß√µes (backoff: {backoff_delay:.1f}s)...")
                time.sleep(wait_time)
            else:
                # Aguardar at√© liberar tokens
                current_tokens = sum(tokens for _, tokens in self.token_usage)
                wait_time = max(60 - (time.time() - min(t for t, _ in self.token_usage)) + 1, backoff_delay)
                print(f"‚è≥ Aguardando {wait_time:.1f}s para liberar tokens (backoff: {backoff_delay:.1f}s)...")
                time.sleep(wait_time)
            
            self._clean_old_requests()
            self._clean_old_tokens()
    
    def _record_request(self, tokens_used: int):
        """Registra uma requisi√ß√£o e seus tokens"""
        current_time = time.time()
        self.request_times.append(current_time)
        self.token_usage.append((current_time, tokens_used))
        
    def call_groq_api(self, prompt: str) -> Optional[str]:
        """Chama a API do Groq para classificar a quest√£o"""
        # Estimar tokens (aproximadamente 1 token = 4 caracteres)
        estimated_tokens = len(prompt) // 4 + 100  # +100 para resposta
        
        # Aguardar se necess√°rio
        self._wait_for_rate_limit(estimated_tokens)
        
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        data = {
            "model": GROQ_MODEL,
            "messages": [
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            "max_tokens": 100,
            "temperature": 0.1
        }
        
        try:
            response = requests.post(GROQ_API_URL, headers=headers, json=data, timeout=30)
            
            if response.status_code == 429:
                print(f"‚ö†Ô∏è  Rate limit atingido. Aplicando backoff exponencial...")
                self._increment_backoff()
                backoff_delay = self._calculate_backoff_delay()
                print(f"‚è≥ Aguardando {backoff_delay:.1f}s (erro #{self.consecutive_errors})...")
                time.sleep(backoff_delay)
                return None
            
            response.raise_for_status()
            
            result = response.json()
            content = result["choices"][0]["message"]["content"].strip()
            
            # Registrar a requisi√ß√£o e tokens usados
            actual_tokens = result.get("usage", {}).get("total_tokens", estimated_tokens)
            self._record_request(actual_tokens)
            
            # Reset do backoff em caso de sucesso
            if self.consecutive_errors > 0:
                print(f"‚úÖ Sucesso! Resetando backoff (erro #{self.consecutive_errors} ‚Üí 0)")
                self._reset_backoff()
            
            # Mostrar status do rate limiting
            self._clean_old_requests()
            self._clean_old_tokens()
            remaining_requests = self.max_requests_per_70s - len(self.request_times)
            current_tokens = sum(tokens for _, tokens in self.token_usage)
            remaining_tokens = self.max_tokens_per_minute - current_tokens
            
            print(f"üìä Rate limit: {remaining_requests} reqs restantes, {remaining_tokens} tokens restantes")
            
            return content
            
        except Exception as e:
            print(f"Erro na API: {e}")
            self._increment_backoff()
            backoff_delay = self._calculate_backoff_delay()
            print(f"‚è≥ Aguardando {backoff_delay:.1f}s antes da pr√≥xima tentativa (erro #{self.consecutive_errors})...")
            time.sleep(backoff_delay)
            return None
    
    def build_classification_prompt(self, question: Dict[str, Any], area: str) -> str:
        """Constr√≥i o prompt para classifica√ß√£o da quest√£o"""
        available_disciplines = AREA_TO_DISCIPLINES.get(area, [])
        
        # Construir informa√ß√µes sobre assets
        assets_info = ""
        if question.get("files"):
            assets_info = f"\nIMAGENS/ASSETS: {', '.join(question['files'])}"
        
        # Construir alternativas
        alternatives_text = ""
        if question.get("alternatives"):
            alternatives_text = "\n".join([
                f"{alt['letter']}) {alt['text']}" 
                for alt in question["alternatives"]
            ])
        
        # Mapear √°rea para nome mais claro
        area_names = {
            "ciencias-humanas": "Ci√™ncias Humanas e suas Tecnologias",
            "ciencias-natureza": "Ci√™ncias da Natureza e suas Tecnologias", 
            "linguagens": "Linguagens, C√≥digos e suas Tecnologias",
            "matematica": "Matem√°tica e suas Tecnologias"
        }
        
        area_display = area_names.get(area, area)
        
        prompt = f"""Classifique esta quest√£o do ENEM em UMA disciplina espec√≠fica.

√ÅREA: {area}
DISCIPLINAS V√ÅLIDAS: {', '.join(available_disciplines)}

ENUNCIADO: {question.get('context', '')}
CONTEXTO: {question.get('alternativesIntroduction', '')}
ALTERNATIVAS: {alternatives_text}{assets_info}

REGRAS:
- Responda APENAS o nome da disciplina
- Use apenas: {', '.join(available_disciplines)}
- N√ÉO explique, N√ÉO justifique
- Exemplo: "geografia" ou "biologia"

RESPOSTA:"""

        return prompt
    
    def extract_discipline_from_response(self, response: str, available_disciplines: List[str]) -> Optional[str]:
        """Extrai o nome da disciplina da resposta da IA"""
        if not response:
            return None
        
        response = response.lower().strip()
        
        # 1. Procurar por disciplinas v√°lidas na resposta (busca exata)
        for discipline in available_disciplines:
            if discipline in response:
                return discipline
        
        # 2. Procurar por varia√ß√µes comuns
        variations = {
            "quimica": ["qu√≠mica", "quimica"],
            "fisica": ["f√≠sica", "fisica"],
            "historia": ["hist√≥ria", "historia"],
            "geografia": ["geografia", "geografia"],
            "filosofia": ["filosofia", "filosofia"],
            "sociologia": ["sociologia", "sociologia"],
            "portugues": ["portugu√™s", "portugues"],
            "literatura": ["literatura", "literatura"],
            "artes": ["arte", "artes"],
            "ingles": ["ingl√™s", "ingles", "english"],
            "espanhol": ["espanhol", "espa√±ol"],
            "matematica": ["matem√°tica", "matematica", "math"]
        }
        
        for discipline, variants in variations.items():
            if discipline in available_disciplines:
                for variant in variants:
                    if variant in response:
                        return discipline
        
        # 3. Tentar extrair a primeira palavra
        words = response.split()
        if words:
            first_word = words[0].strip('.,!?;:')
            if first_word in available_disciplines:
                return first_word
        
        # 4. Procurar por padr√µes como "√©: disciplina" ou "disciplina."
        for discipline in available_disciplines:
            patterns = [f"√©: {discipline}", f"√© {discipline}", f"{discipline}."]
            for pattern in patterns:
                if pattern in response:
                    return discipline
        
        return None
    
    def classify_question(self, question: Dict[str, Any], area: str) -> Optional[str]:
        """Classifica uma quest√£o usando IA"""
        # Auto-classifica√ß√£o para matem√°tica (√°rea s√≥ tem matem√°tica)
        if area == "matematica":
            print(f"üî¢ Auto-classificando matem√°tica (√°rea s√≥ tem matem√°tica)")
            return "matematica"
        
        prompt = self.build_classification_prompt(question, area)
        classification = self.call_groq_api(prompt)
        
        if classification:
            available_disciplines = AREA_TO_DISCIPLINES.get(area, [])
            
            # Extrair disciplina da resposta
            extracted_discipline = self.extract_discipline_from_response(classification, available_disciplines)
            
            if extracted_discipline:
                # Valida√ß√£o adicional: verificar se a disciplina faz sentido para a √°rea
                if self._validate_discipline_for_area(extracted_discipline, area):
                    return extracted_discipline
                else:
                    print(f"‚ö†Ô∏è  Disciplina inv√°lida para √°rea: {extracted_discipline} (√°rea: {area})")
                    return None
            else:
                print(f"‚ö†Ô∏è  N√£o foi poss√≠vel extrair disciplina v√°lida da resposta: {classification[:100]}...")
                print(f"    Disciplinas v√°lidas: {', '.join(available_disciplines)}")
                return None
        
        return None
    
    def _validate_discipline_for_area(self, discipline: str, area: str) -> bool:
        """Valida√ß√£o adicional para garantir que a disciplina faz sentido para a √°rea"""
        validation_rules = {
            "ciencias-humanas": ["historia", "geografia", "filosofia", "sociologia"],
            "ciencias-natureza": ["biologia", "quimica", "fisica"],
            "linguagens": ["portugues", "literatura", "artes", "ingles", "espanhol"],
            "matematica": ["matematica"]
        }
        
        valid_disciplines = validation_rules.get(area, [])
        return discipline in valid_disciplines
    
    def _reorder_json_keys(self, question_data: Dict[str, Any], area: str, discipline: str) -> Dict[str, Any]:
        """Reordena as keys do JSON para colocar 'area' antes de 'discipline'"""
        # Remover as keys antigas se existirem
        question_data.pop("area", None)
        question_data.pop("discipline", None)
        
        # Criar novo dicion√°rio com ordem correta
        reordered = {}
        
        # Adicionar keys na ordem desejada
        for key in ["title", "index", "year", "language"]:
            if key in question_data:
                reordered[key] = question_data[key]
        
        # Adicionar area e discipline
        reordered["area"] = area
        reordered["discipline"] = discipline
        
        # Adicionar o resto das keys
        for key, value in question_data.items():
            if key not in reordered:
                reordered[key] = value
        
        return reordered
    
    def process_question_file(self, question_path: Path, area: str) -> bool:
        """Processa um arquivo de quest√£o individual"""
        try:
            with open(question_path, 'r', encoding='utf-8') as f:
                question_data = json.load(f)
            
            # Verificar se j√° foi processada
            if "area" in question_data and "discipline" in question_data:
                print(f"‚è≠Ô∏è  {question_path.name}: J√° processada ({question_data['area']} ‚Üí {question_data['discipline']})")
                self.skipped_count += 1
                return True
            
            # Classificar a quest√£o
            discipline = self.classify_question(question_data, area)
            
            if discipline:
                # Valida√ß√£o final antes de salvar
                if self._validate_discipline_for_area(discipline, area):
                    # Reordenar o JSON para colocar "area" antes de "discipline"
                    reordered_data = self._reorder_json_keys(question_data, area, discipline)
                    
                    # Salvar o arquivo atualizado
                    with open(question_path, 'w', encoding='utf-8') as f:
                        json.dump(reordered_data, f, ensure_ascii=False, indent=4)
                    
                    print(f"‚úÖ {question_path.name}: {area} ‚Üí {discipline}")
                    return True
                else:
                    error_msg = f"Valida√ß√£o final falhou ({area} ‚Üí {discipline})"
                    print(f"‚ùå {question_path.name}: {error_msg}")
                    self._log_error(question_path, "VALIDATION_ERROR", error_msg, area)
                    self.failed_count += 1
                    return False
            else:
                error_msg = "Falha na classifica√ß√£o da IA"
                print(f"‚ùå {question_path.name}: {error_msg}")
                self._log_error(question_path, "CLASSIFICATION_ERROR", error_msg, area)
                self.failed_count += 1
                return False
                
        except Exception as e:
            error_msg = f"Erro ao processar arquivo: {str(e)}"
            print(f"‚ùå Erro ao processar {question_path}: {e}")
            self._log_error(question_path, "FILE_ERROR", error_msg, area)
            self.failed_count += 1
            return False
    
    def process_year(self, year: int, retry_failed: bool = False, start_question: int = None) -> None:
        """Processa todas as quest√µes de um ano"""
        year_path = self.base_path / "year" / str(year)
        
        if not year_path.exists():
            print(f"‚ùå Diret√≥rio do ano {year} n√£o encontrado")
            return
        
        # Carregar o arquivo principal do ano
        year_file = year_path / "details.json"
        if not year_file.exists():
            print(f"‚ùå Arquivo details.json n√£o encontrado para {year}")
            return
        
        with open(year_file, 'r', encoding='utf-8') as f:
            year_data = json.load(f)
        
        print(f"\nüìÖ Processando ENEM {year}...")
        
        # Carregar progresso anterior
        processed_questions = self._load_progress(year) if not retry_failed else []
        
        # Processar cada quest√£o
        questions = year_data.get("questions", [])
        self.total_count = len(questions)
        
        # Se start_question foi especificado, pular quest√µes iniciais
        if start_question:
            print(f"üéØ Come√ßando a partir da quest√£o {start_question}")
            questions = [q for q in questions if q.get("index", 0) >= start_question]
            print(f"üìä Quest√µes restantes: {len(questions)}")
            # Atualizar total_count para refletir apenas as quest√µes que ser√£o processadas
            self.total_count = len(questions)
        
        for i, question_info in enumerate(questions, 1):
            area = question_info.get("discipline")  # discipline atual √© na verdade a √°rea
            language = question_info.get("language")
            question_index = question_info.get("index")
            
            if not area or not question_index:
                print(f"‚ö†Ô∏è  Quest√£o {i} sem √°rea ou √≠ndice")
                continue
            
            # Determinar o caminho da quest√£o
            if language:
                # Quest√£o de l√≠ngua estrangeira
                question_folder = f"{question_index}-{language}"
            else:
                # Quest√£o normal
                question_folder = str(question_index)
            
            question_path = year_path / "questions" / question_folder / "details.json"
            
            # Verificar se j√° foi processada (exceto se for retry)
            if not retry_failed and str(question_path) in processed_questions:
                print(f"‚è≠Ô∏è  Quest√£o {question_index}: J√° processada anteriormente")
                self.skipped_count += 1
                continue
            
            if question_path.exists():
                # Mostrar contador correto e √≠ndice da quest√£o
                if start_question:
                    print(f"[{i}/{self.total_count}] Processando quest√£o {question_index} (iniciado da {start_question})...")
                else:
                    print(f"[{i}/{self.total_count}] Processando quest√£o {question_index}...")
                
                success = self.process_question_file(question_path, area)
                if success:
                    self.processed_count += 1
                    processed_questions.append(str(question_path))
                    
                    # Salvar progresso a cada 10 quest√µes
                    if self.processed_count % 10 == 0:
                        self._save_progress(year, processed_questions)
            else:
                print(f"‚ö†Ô∏è  Arquivo n√£o encontrado: {question_path}")
                self._log_error(question_path, "FILE_NOT_FOUND", "Arquivo n√£o encontrado", area)
                self.failed_count += 1
        
        # Salvar progresso final
        self._save_progress(year, processed_questions)
        
        print(f"\n‚úÖ Processamento do {year} conclu√≠do!")
        print(f"üìä Quest√µes processadas: {self.processed_count}")
        print(f"üìä Quest√µes puladas: {self.skipped_count}")
        print(f"üìä Quest√µes com erro: {self.failed_count}")
        print(f"üìä Total: {self.processed_count + self.skipped_count + self.failed_count}/{self.total_count}")
        
        if self.failed_count > 0:
            print(f"üìù Log de erros salvo em: {self.log_file}")
            print(f"üí° Para tentar novamente as quest√µes com erro, use: --retry-failed")
    
    def retry_failed_questions(self, year: int = None, start_question: int = None) -> None:
        """Tenta processar novamente as quest√µes que falharam"""
        print("üîÑ Tentando processar novamente quest√µes com erro...")
        
        # Carregar quest√µes com erro do log
        failed_questions = self._load_failed_questions_from_log()
        
        if not failed_questions:
            print("‚úÖ Nenhuma quest√£o com erro encontrada no log!")
            return
        
        # Filtrar por ano se especificado
        if year:
            failed_questions = [q for q in failed_questions if year in str(q)]
            if not failed_questions:
                print(f"‚úÖ Nenhuma quest√£o com erro encontrada para o ano {year}!")
                return
        
        print(f"üìä Encontradas {len(failed_questions)} quest√µes com erro para reprocessar")
        
        # Processar cada quest√£o com erro
        for i, question_path in enumerate(failed_questions, 1):
            question_path = Path(question_path)
            
            if not question_path.exists():
                print(f"‚ö†Ô∏è  Arquivo n√£o encontrado: {question_path}")
                continue
            
            # Carregar a quest√£o para obter a √°rea
            try:
                with open(question_path, 'r', encoding='utf-8') as f:
                    question_data = json.load(f)
                
                # Tentar obter √°rea (pode ser "area" ou "discipline" original)
                area = question_data.get("area") or question_data.get("discipline")
                if not area:
                    print(f"‚ö†Ô∏è  Quest√£o sem √°rea definida: {question_path}")
                    continue
                
                # Extrair o ano e o n√∫mero da quest√£o do caminho do arquivo
                try:
                    # Exemplo de caminho: .../year/2018/questions/115/details.json
                    parts = question_path.parts
                    year = next((p for i, p in enumerate(parts) if p == "year" and i + 1 < len(parts)), None)
                    if year:
                        year_index = parts.index("year") + 1
                        year_value = parts[year_index]
                    else:
                        year_value = "?"
                    # Procurar o n√∫mero da quest√£o
                    if "questions" in parts:
                        q_index = parts.index("questions") + 1
                        question_number = parts[q_index]
                    else:
                        question_number = "?"
                except Exception:
                    year_value = "?"
                    question_number = "?"
                print(f"[{i}/{len(failed_questions)}] Reprocessando quest√£o {question_number} do ano {year_value} ({question_path.name})...")
                
                success = self.process_question_file(question_path, area)
                if success:
                    self.processed_count += 1
                    print(f"‚úÖ {question_path.name}: {area} ‚Üí {question_data.get('discipline', 'N/A')}")
                    # Remover quest√£o do log de erros ap√≥s sucesso
                    self._remove_question_from_error_log(question_path)
                else:
                    print(f"‚ùå {question_path.name}: Falha novamente")
                
            except Exception as e:
                print(f"‚ùå Erro ao carregar {question_path}: {e}")
        
        print(f"\n‚úÖ Retry conclu√≠do!")
        print(f"üìä Quest√µes reprocessadas: {self.processed_count}/{len(failed_questions)}")
        
        # Mostrar estat√≠sticas do log ap√≥s retry
        self._show_log_statistics()
    
    def _remove_question_from_error_log(self, question_path: Path):
        """Remove uma quest√£o espec√≠fica do log de erros ap√≥s processamento bem-sucedido"""
        if not self.log_file.exists():
            return
        
        try:
            with open(self.log_file, 'r', encoding='utf-8') as f:
                lines = f.readlines()
            
            # Filtrar linhas que n√£o cont√™m o caminho da quest√£o
            filtered_lines = []
            removed_count = 0
            
            for line in lines:
                # Verificar se a linha cont√©m o caminho da quest√£o
                if str(question_path) in line:
                    removed_count += 1
                    continue  # Pular esta linha (remover)
                filtered_lines.append(line)
            
            # Reescrever o arquivo sem as linhas removidas
            if removed_count > 0:
                with open(self.log_file, 'w', encoding='utf-8') as f:
                    f.writelines(filtered_lines)
                
                if os.environ.get('NODE_ENV') == 'development':
                    print(f"üóëÔ∏è  Removidas {removed_count} entradas do log para {question_path.name}")
        
        except Exception as e:
            if os.environ.get('NODE_ENV') == 'development':
                print(f"‚ö†Ô∏è  Erro ao remover do log: {e}")
    
    def _show_log_statistics(self):
        """Mostra estat√≠sticas do log de erros"""
        if not self.log_file.exists():
            print("üìã Log de erros: vazio")
            return
        
        try:
            with open(self.log_file, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # Contar entradas de erro
            error_entries = content.count('[CLASSIFICATION_ERROR]')
            warning_entries = content.count('‚ö†Ô∏è')
            
            print(f"üìã Log de erros atualizado:")
            print(f"   ‚Ä¢ Erros de classifica√ß√£o: {error_entries}")
            print(f"   ‚Ä¢ Avisos: {warning_entries}")
            
            if error_entries == 0:
                print("   üéâ Nenhum erro restante no log!")
            else:
                print(f"   ‚ö†Ô∏è  {error_entries} quest√µes ainda com erro")
        
        except Exception as e:
            print(f"‚ö†Ô∏è  Erro ao ler estat√≠sticas do log: {e}")
    
    def _load_failed_questions_from_log(self) -> list:
        """Carrega as quest√µes com erro do arquivo de log"""
        failed_questions = []
        
        if not self.log_file.exists():
            return failed_questions
        
        try:
            with open(self.log_file, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # Dividir por linhas de timestamp para processar cada entrada
            entries = content.split('\n[')
            if entries[0].startswith('['):
                entries[0] = entries[0][1:]  # Remover [ inicial da primeira entrada
            
            for entry in entries:
                if not entry.strip():
                    continue
                
                # Adicionar [ de volta se n√£o tiver
                if not entry.startswith('['):
                    entry = '[' + entry
                
                # Procurar por tipos de erro
                if any(error_type in entry for error_type in ["CLASSIFICATION_ERROR:", "VALIDATION_ERROR:", "FILE_ERROR:"]):
                    # Extrair o caminho da quest√£o usando regex mais robusta
                    import re
                    
                    # Padr√£o para extrair o caminho completo
                    pattern = r'(CLASSIFICATION_ERROR|VALIDATION_ERROR|FILE_ERROR):\s+(.+?)\s+\(√°rea:'
                    match = re.search(pattern, entry)
                    
                    if match:
                        question_path = match.group(2).strip()
                        # Verificar se √© um caminho v√°lido
                        if question_path and ('year' in question_path and 'questions' in question_path):
                            failed_questions.append(question_path)
            
            # Remover duplicatas mantendo ordem
            seen = set()
            unique_questions = []
            for q in failed_questions:
                if q not in seen:
                    seen.add(q)
                    unique_questions.append(q)
            
            return unique_questions
            
        except Exception as e:
            print(f"‚ö†Ô∏è  Erro ao ler log de erros: {e}")
            return []
    
    def show_error_summary(self) -> None:
        """Mostra um resumo dos erros encontrados"""
        if not self.error_log:
            print("‚úÖ Nenhum erro encontrado!")
            return
        
        print(f"\nüìä Resumo de erros ({len(self.error_log)} total):")
        
        # Agrupar por tipo de erro
        error_types = {}
        for error in self.error_log:
            error_type = error["error_type"]
            if error_type not in error_types:
                error_types[error_type] = []
            error_types[error_type].append(error)
        
        for error_type, errors in error_types.items():
            print(f"\n  {error_type}: {len(errors)} erros")
            for error in errors[:3]:  # Mostrar apenas os primeiros 3
                print(f"    - {error['question_path']} (√°rea: {error['area']})")
            if len(errors) > 3:
                print(f"    ... e mais {len(errors) - 3} erros")
        
        print(f"\nüìù Log completo salvo em: {self.log_file}")
    
    def process_all_years(self) -> None:
        """Processa todos os anos dispon√≠veis"""
        years_path = self.base_path / "year"
        
        if not years_path.exists():
            print("‚ùå Diret√≥rio 'year' n√£o encontrado")
            return
        
        # Encontrar todos os anos
        years = []
        for item in years_path.iterdir():
            if item.is_dir() and item.name.isdigit():
                years.append(int(item.name))
        
        years.sort()
        
        print(f"üìö Anos encontrados: {years}")
        
        for year in years:
            self.process_year(year)
            print(f"\n{'='*50}")
    
    def check_all_questions(self) -> None:
        """Verifica todas as quest√µes para validar discipline, area e mapeamentos"""
        print("\nüîç Verificando todas as quest√µes...")
        
        years_path = self.base_path / "year"
        validation_errors = []
        missing_area = []
        missing_discipline = []
        invalid_mapping = []
        file_errors = []
        
        total_questions = 0
        valid_questions = 0
        
        # Estat√≠sticas por √°rea
        area_stats = {}
        discipline_stats = {}
        
        for year_dir in years_path.iterdir():
            if not year_dir.is_dir() or not year_dir.name.isdigit():
                continue
            
            year = int(year_dir.name)
            print(f"üìÖ Verificando {year}...")
            
            year_questions = 0
            year_valid = 0
            
            for question_dir in (year_dir / "questions").iterdir():
                if not question_dir.is_dir():
                    continue
                
                question_file = question_dir / "details.json"
                if not question_file.exists():
                    continue
                
                total_questions += 1
                year_questions += 1
                
                try:
                    with open(question_file, 'r', encoding='utf-8') as f:
                        question_data = json.load(f)
                    
                    area = question_data.get("area")
                    discipline = question_data.get("discipline")
                    
                    # Verificar se tem √°rea
                    if not area:
                        missing_area.append(f"{question_file}: Sem √°rea definida")
                        continue
                    
                    # Verificar se tem disciplina
                    if not discipline:
                        missing_discipline.append(f"{question_file}: Sem disciplina definida (√°rea: {area})")
                        continue
                    
                    # Verificar se a disciplina √© v√°lida para a √°rea
                    valid_disciplines = AREA_TO_DISCIPLINES.get(area, [])
                    if discipline not in valid_disciplines:
                        invalid_mapping.append(
                            f"{question_file}: Disciplina '{discipline}' inv√°lida para √°rea '{area}' "
                            f"(v√°lidas: {', '.join(valid_disciplines)})"
                        )
                        continue
                    
                    # Quest√£o v√°lida
                    valid_questions += 1
                    year_valid += 1
                    
                    # Atualizar estat√≠sticas
                    area_stats[area] = area_stats.get(area, 0) + 1
                    discipline_stats[discipline] = discipline_stats.get(discipline, 0) + 1
                
                except Exception as e:
                    file_errors.append(f"{question_file}: Erro ao ler - {e}")
            
            print(f"   ‚úÖ {year}: {year_valid}/{year_questions} quest√µes v√°lidas")
        
        # Relat√≥rio final
        print(f"\nüìä RELAT√ìRIO DE VERIFICA√á√ÉO")
        print(f"{'='*50}")
        print(f"üìà Total de quest√µes verificadas: {total_questions}")
        print(f"‚úÖ Quest√µes v√°lidas: {valid_questions}")
        print(f"‚ùå Quest√µes com problemas: {total_questions - valid_questions}")
        
        # Problemas encontrados
        if missing_area:
            print(f"\nüö´ Quest√µes sem √°rea ({len(missing_area)}):")
            for error in missing_area[:5]:
                print(f"   - {error}")
            if len(missing_area) > 5:
                print(f"   ... e mais {len(missing_area) - 5} quest√µes")
        
        if missing_discipline:
            print(f"\nüö´ Quest√µes sem disciplina ({len(missing_discipline)}):")
            for error in missing_discipline[:5]:
                print(f"   - {error}")
            if len(missing_discipline) > 5:
                print(f"   ... e mais {len(missing_discipline) - 5} quest√µes")
        
        if invalid_mapping:
            print(f"\nüö´ Mapeamentos inv√°lidos ({len(invalid_mapping)}):")
            for error in invalid_mapping[:5]:
                print(f"   - {error}")
            if len(invalid_mapping) > 5:
                print(f"   ... e mais {len(invalid_mapping) - 5} quest√µes")
        
        if file_errors:
            print(f"\nüö´ Erros de arquivo ({len(file_errors)}):")
            for error in file_errors[:5]:
                print(f"   - {error}")
            if len(file_errors) > 5:
                print(f"   ... e mais {len(file_errors) - 5} erros")
        
        # Estat√≠sticas por √°rea
        if area_stats:
            print(f"\nüìä QUEST√ïES POR √ÅREA:")
            for area, count in sorted(area_stats.items()):
                print(f"   {area}: {count} quest√µes")
        
        # Estat√≠sticas por disciplina
        if discipline_stats:
            print(f"\nüìä QUEST√ïES POR DISCIPLINA:")
            for discipline, count in sorted(discipline_stats.items()):
                print(f"   {discipline}: {count} quest√µes")
        
        # Valida√ß√£o de mapeamentos espec√≠ficos
        print(f"\nüîç VALIDA√á√ÉO DE MAPEAMENTOS:")
        self._validate_specific_mappings()
        
        # Salvar relat√≥rio detalhado
        self._save_validation_report({
            'total_questions': total_questions,
            'valid_questions': valid_questions,
            'missing_area': missing_area,
            'missing_discipline': missing_discipline,
            'invalid_mapping': invalid_mapping,
            'file_errors': file_errors,
            'area_stats': area_stats,
            'discipline_stats': discipline_stats
        })
        
        if total_questions == valid_questions:
            print(f"\nüéâ TODAS AS QUEST√ïES EST√ÉO V√ÅLIDAS!")
        else:
            print(f"\n‚ö†Ô∏è  {total_questions - valid_questions} quest√µes precisam de corre√ß√£o")
    
    def _validate_specific_mappings(self) -> None:
        """Valida mapeamentos espec√≠ficos mencionados pelo usu√°rio"""
        print("   Verificando mapeamentos espec√≠ficos...")
        
        # Mapeamentos que devem ser v√°lidos
        expected_mappings = {
            "linguagens": ["ingles", "espanhol", "portugues", "literatura", "artes"],
            "ciencias-natureza": ["fisica", "quimica", "biologia"],
            "ciencias-humanas": ["historia", "geografia", "filosofia", "sociologia"],
            "matematica": ["matematica"]
        }
        
        years_path = self.base_path / "year"
        mapping_issues = []
        
        for year_dir in years_path.iterdir():
            if not year_dir.is_dir() or not year_dir.name.isdigit():
                continue
            
            for question_dir in (year_dir / "questions").iterdir():
                if not question_dir.is_dir():
                    continue
                
                question_file = question_dir / "details.json"
                if not question_file.exists():
                    continue
                
                try:
                    with open(question_file, 'r', encoding='utf-8') as f:
                        question_data = json.load(f)
                    
                    area = question_data.get("area")
                    discipline = question_data.get("discipline")
                    
                    if not area or not discipline:
                        continue
                    
                    # Verificar mapeamentos espec√≠ficos
                    if area in expected_mappings:
                        valid_disciplines = expected_mappings[area]
                        if discipline not in valid_disciplines:
                            mapping_issues.append(f"{question_file}: {discipline} n√£o deveria estar em {area}")
                
                except Exception:
                    continue
        
        if mapping_issues:
            print(f"   ‚ùå {len(mapping_issues)} mapeamentos incorretos encontrados:")
            for issue in mapping_issues[:3]:
                print(f"      - {issue}")
            if len(mapping_issues) > 3:
                print(f"      ... e mais {len(mapping_issues) - 3}")
        else:
            print("   ‚úÖ Todos os mapeamentos espec√≠ficos est√£o corretos")
    
    def _save_validation_report(self, report_data: dict) -> None:
        """Salva relat√≥rio detalhado de valida√ß√£o"""
        report_file = self.base_path / "validation_report.json"
        
        try:
            with open(report_file, 'w', encoding='utf-8') as f:
                json.dump(report_data, f, ensure_ascii=False, indent=2)
            print(f"\nüìÑ Relat√≥rio detalhado salvo em: {report_file}")
        except Exception as e:
            print(f"‚ö†Ô∏è  Erro ao salvar relat√≥rio: {e}")

    def validate_classifications(self) -> None:
        """Valida as classifica√ß√µes feitas (fun√ß√£o original mantida para compatibilidade)"""
        print("\nüîç Validando classifica√ß√µes...")
        
        years_path = self.base_path / "year"
        validation_errors = []
        
        for year_dir in years_path.iterdir():
            if not year_dir.is_dir() or not year_dir.name.isdigit():
                continue
            
            year = int(year_dir.name)
            print(f"Validando {year}...")
            
            for question_dir in (year_dir / "questions").iterdir():
                if not question_dir.is_dir():
                    continue
                
                question_file = question_dir / "details.json"
                if not question_file.exists():
                    continue
                
                try:
                    with open(question_file, 'r', encoding='utf-8') as f:
                        question_data = json.load(f)
                    
                    area = question_data.get("area")
                    discipline = question_data.get("discipline")
                    
                    if not area or not discipline:
                        validation_errors.append(f"{question_file}: Sem √°rea ou disciplina")
                        continue
                    
                    # Verificar se a disciplina √© v√°lida para a √°rea
                    valid_disciplines = AREA_TO_DISCIPLINES.get(area, [])
                    if discipline not in valid_disciplines:
                        validation_errors.append(
                            f"{question_file}: Disciplina '{discipline}' inv√°lida para √°rea '{area}'"
                        )
                
                except Exception as e:
                    validation_errors.append(f"{question_file}: Erro ao ler - {e}")
        
        if validation_errors:
            print(f"\n‚ùå {len(validation_errors)} erros encontrados:")
            for error in validation_errors[:10]:  # Mostrar apenas os primeiros 10
                print(f"  - {error}")
            if len(validation_errors) > 10:
                print(f"  ... e mais {len(validation_errors) - 10} erros")
        else:
            print("‚úÖ Todas as classifica√ß√µes est√£o v√°lidas!")

def main():
    parser = argparse.ArgumentParser(description="Filtrar quest√µes do ENEM por disciplina usando IA")
    parser.add_argument("--api-key", help="Chave da API do Groq (obrigat√≥ria apenas para processamento)")
    parser.add_argument("--year", type=int, help="Processar apenas um ano espec√≠fico")
    parser.add_argument("--validate", action="store_true", help="Apenas validar classifica√ß√µes existentes")
    parser.add_argument("--check-all", action="store_true", help="Verificar todas as quest√µes e validar discipline/area")
    parser.add_argument("--retry-failed", action="store_true", help="Tentar novamente quest√µes que falharam")
    parser.add_argument("--show-errors", action="store_true", help="Mostrar resumo de erros")
    parser.add_argument("--start-question", type=int, help="Come√ßar a partir de uma quest√£o espec√≠fica (ex: 105)")
    parser.add_argument("--base-path", default=".", help="Caminho base dos arquivos")
    
    args = parser.parse_args()
    
    # Inicializar o filtro (API key s√≥ √© necess√°ria para processamento)
    api_key = args.api_key or "dummy_key"  # Para modos que n√£o precisam de API
    filter_tool = QuestionFilter(api_key, args.base_path)
    
    if args.check_all:
        # Verificar todas as quest√µes
        filter_tool.check_all_questions()
    elif args.validate:
        # Apenas validar
        filter_tool.validate_classifications()
    elif args.retry_failed:
        # Verificar se API key foi fornecida para retry
        if not args.api_key:
            print("‚ùå Chave da API do Groq √© obrigat√≥ria para --retry-failed")
            print("Use: python filter_questions_ai.py --api-key SUA_CHAVE_AQUI --retry-failed")
            return
        # Tentar novamente quest√µes com erro
        filter_tool.retry_failed_questions(args.year, args.start_question)
    elif args.show_errors:
        # Mostrar resumo de erros
        filter_tool.show_error_summary()
    elif args.year:
        # Verificar se API key foi fornecida para processamento
        if not args.api_key:
            print("‚ùå Chave da API do Groq √© obrigat√≥ria para processamento")
            print("Use: python filter_questions_ai.py --api-key SUA_CHAVE_AQUI --year 2009")
            return
        # Processar ano espec√≠fico
        filter_tool.process_year(args.year, start_question=args.start_question)
    else:
        # Verificar se API key foi fornecida para processamento
        if not args.api_key:
            print("‚ùå Chave da API do Groq √© obrigat√≥ria para processamento")
            print("Use: python filter_questions_ai.py --api-key SUA_CHAVE_AQUI")
            print("   Ou use --check-all para apenas verificar quest√µes existentes")
            return
        # Processar todos os anos
        if args.start_question:
            print(f"‚ö†Ô∏è  --start-question s√≥ funciona com --year")
            print("   Use: python filter_questions_ai.py --api-key SUA_CHAVE --year 2009 --start-question 105")
            return
        filter_tool.process_all_years()
    
    print(f"\nüéâ Processo conclu√≠do!")
    print(f"üìä Total de quest√µes processadas: {filter_tool.processed_count}")
    print(f"üìä Total de quest√µes puladas: {filter_tool.skipped_count}")
    print(f"üìä Total de quest√µes com erro: {filter_tool.failed_count}")
    
    if filter_tool.failed_count > 0:
        print(f"\nüí° Para tentar novamente as quest√µes com erro:")
        print(f"   python filter_questions_ai.py --api-key SUA_CHAVE --retry-failed")
        print(f"   python filter_questions_ai.py --api-key SUA_CHAVE --show-errors")
    
    print(f"\nüí° Outros comandos √∫teis:")
    print(f"   python filter_questions_ai.py --check-all  # Verificar todas as quest√µes")
    print(f"   python filter_questions_ai.py --validate   # Validar classifica√ß√µes")

if __name__ == "__main__":
    main()
